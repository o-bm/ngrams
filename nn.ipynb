{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a6dedd34-ea28-4a7b-8208-d7cd19af7904",
   "metadata": {},
   "outputs": [],
   "source": [
    "words = open('names.txt', 'r').read().splitlines()\n",
    "chars = sorted(list(set(\"\".join(words))))\n",
    "stoi = {c:i+1 for i,c in enumerate(chars)}\n",
    "stoi['.'] = 0\n",
    "itos = {i:s for s,i in stoi.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "d4115d2d-cb7e-4073-9e22-666880ea01be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of examples:  228146\n"
     ]
    }
   ],
   "source": [
    "# create training set\n",
    "# we want to predict bigram ch1,ch2  \n",
    "#x=ch1 (what we take as input to nn)\n",
    "#y=ch2 (what we want to predict)\n",
    "\n",
    "xs = []\n",
    "ys = []\n",
    "for word in words:\n",
    "    chs = ['.'] + list(word) + ['.']\n",
    "    for ch1, ch2 in zip(chs, chs[1:]):\n",
    "        xs.append(stoi[ch1])\n",
    "        ys.append(stoi[ch2])\n",
    "\n",
    "# tensor need one hot / (float or int..) not strs..\n",
    "# tensor.Tensor float, tensor.tensor infers dtype\n",
    "xs = torch.tensor(xs)\n",
    "ys = torch.tensor(ys)\n",
    "num = xs.nelement()\n",
    "print(\"Number of examples: \", num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "3f0a08c6-3b11-41d2-9d21-566ccb1ceec5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# init network\n",
    "g = torch.Generator().manual_seed(2147483647)\n",
    "W = torch.randn((27,27), generator=g, requires_grad=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "039ecc56-6dd9-43d7-906a-414dc5c446ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.594835042953491\n",
      "3.277048110961914\n",
      "3.0970399379730225\n",
      "2.9813578128814697\n",
      "2.8994791507720947\n",
      "2.839292526245117\n",
      "2.793339490890503\n",
      "2.756934404373169\n",
      "2.727195978164673\n",
      "2.702320098876953\n",
      "2.6811399459838867\n",
      "2.6628754138946533\n",
      "2.6469788551330566\n",
      "2.6330466270446777\n",
      "2.6207664012908936\n",
      "2.6098873615264893\n",
      "2.600203275680542\n",
      "2.5915420055389404\n",
      "2.583759069442749\n",
      "2.5767338275909424\n",
      "2.570364236831665\n",
      "2.5645649433135986\n",
      "2.5592634677886963\n",
      "2.55439829826355\n",
      "2.5499181747436523\n",
      "2.54577898979187\n",
      "2.5419435501098633\n",
      "2.538379430770874\n",
      "2.535060167312622\n",
      "2.5319619178771973\n",
      "2.529064893722534\n",
      "2.526350975036621\n",
      "2.523804187774658\n",
      "2.521411180496216\n",
      "2.5191597938537598\n",
      "2.517038345336914\n",
      "2.5150375366210938\n",
      "2.5131478309631348\n",
      "2.5113611221313477\n",
      "2.509669303894043\n",
      "2.5080666542053223\n",
      "2.5065460205078125\n",
      "2.5051019191741943\n",
      "2.5037293434143066\n",
      "2.50242280960083\n",
      "2.501178503036499\n",
      "2.4999921321868896\n",
      "2.4988596439361572\n",
      "2.4977777004241943\n",
      "2.4967432022094727\n",
      "2.495753288269043\n",
      "2.494805097579956\n",
      "2.493896484375\n",
      "2.4930241107940674\n",
      "2.492187023162842\n",
      "2.491382360458374\n",
      "2.4906086921691895\n",
      "2.4898641109466553\n",
      "2.489147186279297\n",
      "2.4884564876556396\n",
      "2.487790107727051\n",
      "2.487147092819214\n",
      "2.4865264892578125\n",
      "2.485926866531372\n",
      "2.485347032546997\n",
      "2.4847865104675293\n",
      "2.484243869781494\n",
      "2.483718156814575\n",
      "2.4832098484039307\n",
      "2.4827160835266113\n",
      "2.4822380542755127\n",
      "2.481774091720581\n",
      "2.481323719024658\n",
      "2.480886459350586\n",
      "2.480462074279785\n",
      "2.4800491333007812\n",
      "2.4796478748321533\n",
      "2.4792580604553223\n",
      "2.4788787364959717\n",
      "2.4785094261169434\n",
      "2.4781501293182373\n",
      "2.4778003692626953\n",
      "2.47745943069458\n",
      "2.4771273136138916\n",
      "2.476803779602051\n",
      "2.4764883518218994\n",
      "2.4761807918548584\n",
      "2.4758808612823486\n",
      "2.475588083267212\n",
      "2.4753024578094482\n",
      "2.4750237464904785\n",
      "2.4747517108917236\n",
      "2.4744858741760254\n",
      "2.474226236343384\n",
      "2.4739725589752197\n",
      "2.473724603652954\n",
      "2.473482370376587\n",
      "2.473245859146118\n",
      "2.4730138778686523\n",
      "2.472787618637085\n"
     ]
    }
   ],
   "source": [
    "# grad desc\n",
    "alpha = 50\n",
    "for k in range(100):\n",
    "    # each row in xenc @ W gives us probabilities of what comes after x_i for each of 27 possible next char. \n",
    "    # lets interpret it as log counts, then we take exp (to give us bet 0-1 and then we can take softmax\n",
    "    # forward pass\n",
    "    xenc = F.one_hot(xs, num_classes=27).float()\n",
    "    logits = xenc @ W # log-counts\n",
    "    counts = (xenc @ W).exp()\n",
    "    probs = counts / counts.sum(1, keepdims=True) # probs for next char given example\n",
    "    loss = -probs[torch.arange(num), ys].log().mean()\n",
    "    print(loss.item())\n",
    "    #backward pass\n",
    "    W.grad = None # set to zero\n",
    "    loss.backward() #pytorch keeps computational graph\n",
    "    #update\n",
    "    W.data += -alpha * W.grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "543893ad-fa19-41bf-a6ea-559a3a3828d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# What do we expect it to converge to?\n",
    "# Lower NLL better.. but whats the best we can do? That is the probability of observing the data we are given, that is the maximum likelihood\n",
    "# 2.47 loss is the same loss we got when we empirical counted and calculated our NLL. that is the prob of our observed data.\n",
    "# The NN method scales much better.. dont need to load all the counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "bc8f3c4b-583c-453c-980d-bba275609f73",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1.)"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# each row in xenc @ W gives us probabilities of what comes after x_i for each of 27 possible next char. \n",
    "# lets interpret it as log counts, then we take exp (to give us bet 0-1 and then we can take softmax\n",
    "\n",
    "logits = xenc @ W # log-counts\n",
    "counts = (xenc @ W).exp()\n",
    "probs = counts / counts.sum(1, keepdims=True)\n",
    "probs[0].sum()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "876f7f62-9747-4055-89be-b2a387c59f56",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0.])"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xenc[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "15118d43-cfa3-428f-8d83-1c60c645c337",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-0.4291, -0.1845,  0.2726,  1.5352,  0.6093,  0.5183, -0.2676, -0.0259,\n",
       "        -0.9776,  0.2014,  0.2593,  0.3575, -0.6476,  0.4527,  1.5306, -0.8503,\n",
       "        -1.0024,  0.0538, -0.8991,  2.1286,  0.9050, -0.3684,  0.7863, -0.0198,\n",
       "        -0.7577,  1.2114,  1.1810])"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0eb03f0f-02d6-4564-9814-64f6525def2f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "91b83210-e5fb-40dc-bac6-0307d1f7ee83",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x116f1d940>"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "plt.imshow(xenc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "a1782d8e-7ffe-465c-a328-a614f966ad8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating a training set of bigrams\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (venv)",
   "language": "python",
   "name": "venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
